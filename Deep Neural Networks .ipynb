{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VIBIN\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "UsageError: Line magic function `%load_ext_autoreload` not found.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from dnn_utils_v2 import *\n",
    "from dnn_utils_v2 import load_data\n",
    "import time \n",
    "from PIL import Image\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "np.random.seed(1)\n",
    "\n",
    "from testCases_v2 import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext_autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    np.random.seed(3)\n",
    "    W1 = np.random.randn(n_h, n_x) *.01\n",
    "    b1 = np.zeros((n_h,1))\n",
    "    W2 = np.random.randn(n_y,n_h)*.01\n",
    "    b2 = np.zeros((n_y, 1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[ 0.01788628  0.0043651 ]\n",
      " [ 0.00096497 -0.01863493]]\n",
      "b1 = [[0.]\n",
      " [0.]]\n",
      "W2 = [[-0.00277388 -0.00354759]]\n",
      "b2 = [[0.]]\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters(2,2,1)\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model's structure has $L-1$ layers using a ReLU activation function followed by an output layer with a sigmoid activation function.\n",
    "We will store $n^{[l]}$, the number of units in different layers, in a variable layer_dims. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    np.random.seed(1)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1])*0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l],1))\n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "    \n",
    "    return parameters    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[ 0.01788628  0.0043651   0.00096497 -0.01863493 -0.00277388]\n",
      " [-0.00354759 -0.00082741 -0.00627001 -0.00043818 -0.00477218]\n",
      " [-0.01313865  0.00884622  0.00881318  0.01709573  0.00050034]\n",
      " [-0.00404677 -0.0054536  -0.01546477  0.00982367 -0.01101068]]\n",
      "b1 = [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "W2 = [[-0.01185047 -0.0020565   0.01486148  0.00236716]\n",
      " [-0.01023785 -0.00712993  0.00625245 -0.00160513]\n",
      " [-0.00768836 -0.00230031  0.00745056  0.01976111]]\n",
      "b2 = [[0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parameters = initialize_parameters_deep([5,4,3])\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    Z = np.dot(W, A) + b\n",
    "    \n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z = [[ 3.26295337 -1.23429987]]\n"
     ]
    }
   ],
   "source": [
    "A, W, b = linear_forward_test_case()\n",
    "\n",
    "Z, linear_cache = linear_forward(A, W, b)\n",
    "print(\"Z = \" + str(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "     \n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With sigmoid: A = [[0.96890023 0.11013289]]\n",
      "With ReLU: A = [[3.43896131 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "A_prev, W, b = linear_activation_forward_test_case()\n",
    "\n",
    "A, linear_activation_cache = linear_activation_forward(A_prev, W, b, activation = \"sigmoid\")\n",
    "print(\"With sigmoid: A = \" + str(A))\n",
    "\n",
    "A, linear_activation_cache = linear_activation_forward(A_prev, W, b, activation = \"relu\")\n",
    "print(\"With ReLU: A = \" + str(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2\n",
    "    #implement L-1 layers of linear - > relu\n",
    "    for l in range(1, L):\n",
    "        A_prev = A\n",
    "        A, cache = linear_activation_forward(A_prev,\n",
    "                                             parameters['W' + str(l)],\n",
    "                                             parameters['b' + str(l)],\n",
    "                                             activation=\"relu\")\n",
    "        \n",
    "        caches.append(cache)\n",
    "        \n",
    "    # implement last sigmoid layer \n",
    "    AL, cache = linear_activation_forward(A,\n",
    "                                         parameters['W'+str(L)],\n",
    "                                         parameters['b'+str(L)],\n",
    "                                         activation = \"sigmoid\")\n",
    "    \n",
    "    caches.append(cache)\n",
    "    \n",
    "    return AL, caches\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    m = Y.shape[1]\n",
    "    \n",
    "    cost = (-1./m) * np.sum(np.multiply(Y, np.log(AL)) + np.multiply((1-Y), np.log(1-AL)))\n",
    "    cost = np.squeeze(cost)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    \n",
    "    dW = (1/m) * np.dot(dZ, cache[0].T) \n",
    "    db = (1/m) * np.sum(dZ, axis = 1, keepdims = True)\n",
    "    dA_prev = np.dot(cache[1].T, dZ)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    \n",
    "    grads = {}\n",
    "    L = len(caches)\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape)\n",
    "    \n",
    "    dAL = -(np.divide(Y,AL) - np.divide(1-Y,1-AL))\n",
    "    \n",
    "    current_cache = caches[-1]\n",
    "    \n",
    "    grads[\"dA\"+str(L)], grads[\"dW\"+str(L)], grads[\"db\"+str(L)] = linear_activation_backward(dAL, current_cache, activation = \"sigmoid\")\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        \n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\"+str(l+2)], current_cache, activation = \"relu\")\n",
    "        grads[\"dA\" + str(l + 1)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    L = len(parameters) //2\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_orig, train_y, test_x_orig, test_y, classes = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 0. It's a non-catpicture\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29bcff70ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 10\n",
    "plt.imshow(train_x_orig[index])\n",
    "print(\"y = \" + str(train_y[0,index]) + \". It's a \" + classes[train_y[0,index]].decode(\"utf-8\") + \"picture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 209\n",
      "Number of testing examples: 50\n",
      "Each image is of size: (64, 64, 3)\n",
      "train_x_orig shape: (209, 64, 64, 3)\n",
      "train_y shape: (1, 209)\n",
      "test_x_orig shape: (50, 64, 64, 3)\n",
      "test_y shape: (1, 50)\n"
     ]
    }
   ],
   "source": [
    "m_train = train_x_orig.shape[0]\n",
    "num_px = train_x_orig.shape[1]\n",
    "m_test  = test_x_orig.shape[0]\n",
    "\n",
    "print (\"Number of training examples: \" + str(m_train))\n",
    "print (\"Number of testing examples: \" + str(m_test))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"train_x_orig shape: \" + str(train_x_orig.shape))\n",
    "print (\"train_y shape: \" + str(train_y.shape))\n",
    "print (\"test_x_orig shape: \" + str(test_x_orig.shape))\n",
    "print (\"test_y shape: \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x's shape: (12288, 209)\n",
      "test_x's shape: (12288, 50)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the training and test examples \n",
    "train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T   # The \"-1\" makes reshape flatten the remaining dimensions\n",
    "test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n",
    "\n",
    "# Standardize data to have feature values between 0 and 1.\n",
    "train_x = train_x_flatten/255.\n",
    "test_x = test_x_flatten/255.\n",
    "\n",
    "print (\"train_x's shape: \" + str(train_x.shape))\n",
    "print (\"test_x's shape: \" + str(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_model(X,Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost = False):\n",
    "    np.random.seed(1)\n",
    "    costs = []\n",
    "    \n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    for i in range(0, num_iterations):\n",
    "        \n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "        cost = compute_cost(AL, Y)\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate= learning_rate)\n",
    "        \n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"Cost after iteration %i: %f\"%(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learnign rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693149\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (20,209) (20,12288) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-05d509344b64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlayers_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m12288\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#  5-layer model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mL_layer_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers_dims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-aa8e16f056a9>\u001b[0m in \u001b[0;36mL_layer_model\u001b[1;34m(X, Y, layers_dims, learning_rate, num_iterations, print_cost)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mAL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mL_model_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mL_model_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-1dd348188222>\u001b[0m in \u001b[0;36mL_model_forward\u001b[1;34m(X, parameters)\u001b[0m\n\u001b[0;32m      9\u001b[0m                                              \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                                              \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                                              activation=\"relu\")\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mcaches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-e3a137dd8842>\u001b[0m in \u001b[0;36mlinear_activation_forward\u001b[1;34m(A_prev, W, b, activation)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m# Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m### START CODE HERE ### (≈ 2 lines of code)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mZ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinear_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m### END CODE HERE ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-51-2159bd376607>\u001b[0m in \u001b[0;36mlinear_forward\u001b[1;34m(A, W, b)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlinear_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (20,209) (20,12288) "
     ]
    }
   ],
   "source": [
    "layers_dims = [12288, 20, 7, 5, 1] #  5-layer model\n",
    "parameters = L_layer_model(train_x, train_y, layers_dims, num_iterations = 2500, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[ 0.01788628  0.0043651   0.00096497 -0.01863493 -0.00277388]\n",
      " [-0.00354759 -0.00082741 -0.00627001 -0.00043818 -0.00477218]\n",
      " [-0.01313865  0.00884622  0.00881318  0.01709573  0.00050034]\n",
      " [-0.00404677 -0.0054536  -0.01546477  0.00982367 -0.01101068]]\n",
      "b1 = [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "W2 = [[-0.01185047 -0.0020565   0.01486148  0.00236716]\n",
      " [-0.01023785 -0.00712993  0.00625245 -0.00160513]\n",
      " [-0.00768836 -0.00230031  0.00745056  0.01976111]]\n",
      "b2 = [[0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Implements a two-layer neural network: LINEAR->RELU->LINEAR->SIGMOID.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (n_x, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    layers_dims -- dimensions of the layers (n_x, n_h, n_y)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- If set to True, this will print the cost every 100 iterations \n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary containing W1, W2, b1, and b2\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    grads = {}\n",
    "    costs = []                              # to keep track of the cost\n",
    "    m = X.shape[1]                           # number of examples\n",
    "    (n_x, n_h, n_y) = layers_dims\n",
    "    \n",
    "    # Initialize parameters dictionary, by calling one of the functions you'd previously implemented\n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Get W1, b1, W2 and b2 from the dictionary parameters.\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: LINEAR -> RELU -> LINEAR -> SIGMOID. Inputs: \"X, W1, b1\". Output: \"A1, cache1, A2, cache2\".\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        A1, cache1 = linear_activation_forward(X, W1, b1, activation='relu')\n",
    "        A2, cache2 = linear_activation_forward(A1, W2, b2, activation='sigmoid')\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Compute cost\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        cost = compute_cost(A2, Y)\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Initializing backward propagation\n",
    "        dA2 = - (np.divide(Y, A2) - np.divide(1 - Y, 1 - A2))\n",
    "        \n",
    "        # Backward propagation. Inputs: \"dA2, cache2, cache1\". Outputs: \"dA1, dW2, db2; also dA0 (not used), dW1, db1\".\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        dA1, dW2, db2 = linear_activation_backward(dA2, cache2, activation='sigmoid')\n",
    "        dA0, dW1, db1 = linear_activation_backward(dA1, cache1, activation='relu')\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Set grads['dWl'] to dW1, grads['db1'] to db1, grads['dW2'] to dW2, grads['db2'] to db2\n",
    "        grads['dW1'] = dW1\n",
    "        grads['db1'] = db1\n",
    "        grads['dW2'] = dW2\n",
    "        grads['db2'] = db2\n",
    "        \n",
    "        # Update parameters.\n",
    "        ### START CODE HERE ### (approx. 1 line of code)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate=learning_rate)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # Retrieve W1, b1, W2, b2 from parameters\n",
    "        W1 = parameters[\"W1\"]\n",
    "        b1 = parameters[\"b1\"]\n",
    "        W2 = parameters[\"W2\"]\n",
    "        b2 = parameters[\"b2\"]\n",
    "        \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "       \n",
    "    # plot the cost\n",
    "\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSTANTS DEFINING THE MODEL ####\n",
    "n_x = 12288     # num_px * num_px * 3\n",
    "n_h = 7\n",
    "n_y = 1\n",
    "layers_dims = (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b :[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "w :[[ 0.01788628  0.0043651   0.00096497 ...  0.00742033  0.00777721\n",
      "  -0.02044101]\n",
      " [-0.02034741 -0.01277108 -0.00845047 ... -0.01592858  0.01189758\n",
      "   0.0136909 ]\n",
      " [ 0.00736324  0.01040032 -0.00610759 ... -0.00719972  0.01342522\n",
      "  -0.00194119]\n",
      " ...\n",
      " [-0.00376099  0.0047808   0.01337956 ...  0.00258237  0.00470035\n",
      "  -0.0088996 ]\n",
      " [ 0.02287234 -0.01013267  0.00166333 ...  0.0135046   0.01122616\n",
      "  -0.01048173]\n",
      " [ 0.00369967 -0.00146788  0.00990617 ... -0.00549949 -0.00973773\n",
      "  -0.00078118]]\n",
      "A :[[0.06666667 0.76862745 0.32156863 ... 0.56078431 0.08627451 0.03137255]\n",
      " [0.12156863 0.75294118 0.27843137 ... 0.60784314 0.09411765 0.10980392]\n",
      " [0.21960784 0.74509804 0.26666667 ... 0.64705882 0.09019608 0.20784314]\n",
      " ...\n",
      " [0.         0.32156863 0.54117647 ... 0.33333333 0.01568627 0.        ]\n",
      " [0.         0.31372549 0.55294118 ... 0.41960784 0.01960784 0.        ]\n",
      " [0.         0.31764706 0.55686275 ... 0.58431373 0.         0.        ]]\n",
      "b :[[0.]]\n",
      "w :[[ 0.0003273   0.00394633 -0.01763724 -0.01225417 -0.00218911 -0.00223225\n",
      "   0.00571419]]\n",
      "A :[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.27152867 0.         ... 0.19389626 0.08098635 0.        ]\n",
      " [0.         0.         0.         ... 0.19912612 0.09527905 0.        ]\n",
      " ...\n",
      " [0.25009935 0.05914053 0.00832027 ... 0.37397917 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.1899669  0.        ]\n",
      " [0.12094382 0.         0.         ... 0.         0.01627021 0.07464331]]\n",
      "Cost after iteration 0: 0.6923799160908503\n",
      "b :[[ 0.01788628  0.0043651   0.00096497 ...  0.00742033  0.00777721\n",
      "  -0.02044101]\n",
      " [-0.02034829 -0.01277238 -0.00845114 ... -0.01592971  0.01189604\n",
      "   0.01369011]\n",
      " [ 0.00736711  0.01040574 -0.00610154 ... -0.00719447  0.01343221\n",
      "  -0.0019352 ]\n",
      " ...\n",
      " [-0.00376051  0.00478149  0.01338026 ...  0.00258327  0.00470137\n",
      "  -0.00889882]\n",
      " [ 0.0228727  -0.01013212  0.00166369 ...  0.01350486  0.01122653\n",
      "  -0.01048158]\n",
      " [ 0.00369774 -0.00147032  0.00990432 ... -0.00550297 -0.00974117\n",
      "  -0.00078315]]\n",
      "w :[[ 0.01788628  0.0043651   0.00096497 ...  0.00742033  0.00777721\n",
      "  -0.02044101]\n",
      " [-0.02034785 -0.01277173 -0.00845081 ... -0.01592915  0.01189681\n",
      "   0.0136905 ]\n",
      " [ 0.00736517  0.01040303 -0.00610456 ... -0.0071971   0.01342871\n",
      "  -0.00193819]\n",
      " ...\n",
      " [-0.00376075  0.00478114  0.01337991 ...  0.00258282  0.00470086\n",
      "  -0.00889921]\n",
      " [ 0.02287252 -0.0101324   0.00166351 ...  0.01350473  0.01122634\n",
      "  -0.01048165]\n",
      " [ 0.00369871 -0.0014691   0.00990525 ... -0.00550123 -0.00973945\n",
      "  -0.00078216]]\n",
      "A :[[0.06666667 0.76862745 0.32156863 ... 0.56078431 0.08627451 0.03137255]\n",
      " [0.12156863 0.75294118 0.27843137 ... 0.60784314 0.09411765 0.10980392]\n",
      " [0.21960784 0.74509804 0.26666667 ... 0.64705882 0.09019608 0.20784314]\n",
      " ...\n",
      " [0.         0.32156863 0.54117647 ... 0.33333333 0.01568627 0.        ]\n",
      " [0.         0.31372549 0.55294118 ... 0.41960784 0.01960784 0.        ]\n",
      " [0.         0.31764706 0.55686275 ... 0.58431373 0.         0.        ]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (7,209) (7,12288) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-f2297765406a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtwo_layer_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_cost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-42-02267d8c632a>\u001b[0m in \u001b[0;36mtwo_layer_model\u001b[1;34m(X, Y, layers_dims, learning_rate, num_iterations, print_cost)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;31m# Forward propagation: LINEAR -> RELU -> LINEAR -> SIGMOID. Inputs: \"X, W1, b1\". Output: \"A1, cache1, A2, cache2\".\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m### START CODE HERE ### (≈ 2 lines of code)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mA1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_activation_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0mA2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_activation_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;31m### END CODE HERE ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-e3a137dd8842>\u001b[0m in \u001b[0;36mlinear_activation_forward\u001b[1;34m(A_prev, W, b, activation)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m# Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m### START CODE HERE ### (≈ 2 lines of code)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mZ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinear_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m### END CODE HERE ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-ae83b3477878>\u001b[0m in \u001b[0;36mlinear_forward\u001b[1;34m(A, W, b)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"w :\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"A :\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (7,209) (7,12288) "
     ]
    }
   ],
   "source": [
    "parameters = two_layer_model(train_x, train_y, layers_dims = (n_x, n_h, n_y), num_iterations = 2500, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
